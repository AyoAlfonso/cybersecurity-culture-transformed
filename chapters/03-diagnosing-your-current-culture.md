# Chapter 3: Diagnosing Your Current Culture

## **3.0 The Mirror and the Map: Seeing Your True Reflection**

Imagine standing at the edge of a vast, unfamiliar forest—the kind that holds both promise and peril. You have a destination in mind: a resilient security culture where every individual acts as a guardian. You feel the urgency to push forward, to start planting new processes and launching training programs. But to charge into this terrain without first understanding its contours would be to risk everything. You might water barren ground while missing fertile soil, or build defences where no threat exists.

This chapter is founded on a simple, non-negotiable truth: 

***“Effective action is impossible without honest diagnosis”.*** 

It is the critical, foundational step that cannot be skipped. Just as a doctor must diagnose before prescribing, and a farmer must test the soil before sowing, a leader must understand the cultural landscape before attempting to transform it. To do otherwise is to waste precious resources and, more importantly, to risk alienating the very people you need to engage.

We must move beyond the realm of assumptions and anecdotes. The stories we tell ourselves that “Our people are security-conscious,” or “Middle management doesn’t care” are often incomplete, distorted by our own biases and limited viewpoints. They are like guessing the contours of the forest from a single, foggy glimpse. True insight requires evidence. It demands that we replace “I think” with “I know,” by systematically gathering data that reveals the complex interplay of knowledge, attitudes, behaviours, and social dynamics that define your organisation’s security reality.

The ultimate goal of this diagnostic journey is to create a cultural map. This is not a simple chart of “good” or “bad” areas. It is a rich, detailed portrait that reveals both the fertile ground, the teams already demonstrating shared responsibility, the leaders who model secure behaviour and the barren soil, the departments rife with fear, the processes that incentivise risky workarounds. This map does not judge; it illuminates. It shows you precisely where to nurture, where to build, and where to intervene.

By looking clearly into the mirror of data and unrolling the map of understanding, you move from reactive guessing to proactive strategy. You equip yourself not with a blunt instrument, but with a surgeon’s scalpel, capable of precise, effective interventions. Let us now begin the most important work: seeing your true reflection, so you can plot the course to where you truly need to be.

 

## **3.1. Defining the Diagnostic Scope: What Are We Actually Measuring?**

Going on a diagnostic journey without a clear scope is a bit like walking into the supermarket hungry and without a shopping list. You end up picking up a bit of everything that catches your eye, only to realise once you’re home that you’ve forgotten the basics and probably spent more than you intended. In much the same way, isolated data points might seem interesting on their own, but they rarely reveal the deeper, interconnected relationships that shape the environment.

To move beyond scattered data and towards genuine understanding, we first need to define what we’re trying to measure: the substance of culture itself. What are its essential ingredients? A meaningful diagnosis of security culture cannot hinge on a single metric, it must instead explore the dynamic interplay between four fundamental pillars that together form the foundation of an organisation’s security posture.

**The Four Pillars of Cultural Understanding**

There is an Akan proverb that says, "The spider's web is not woven by one thread." Similarly, a true understanding of security culture is not built from a single perspective or metric. The comprehensive framework for diagnosis encompasses four interconnected elements: Knowledge, Attitudes, Behaviours, and Enabler \- the KABE model that provides this multi-threaded framework for understanding the complete cultural picture within an organisation.

**Add Image here: Diagram showing four interlocking circles labeled Knowledge, Attitudes, Behaviours, and Enablers**

**Figure 3.1 \- The KABE Model**

**\<insert Figure 3.1\>**

***Knowledge*** forms the foundational layer of this model. It pertains to what employees objectively know about security policies, recognised threats, and correct procedures. This includes understanding of password policies, ability to identify phishing attempts, knowledge of data classification procedures, and awareness of incident reporting protocols. This is the most straightforward element to measure, often accomplished through quizzes, knowledge tests, or direct questions during interviews. However, it is also the least predictive of actual security resilience. An employee can recite the company password policy from memory yet consistently fail to apply it in practice, revealing the critical gap between knowing and doing that plagues many security programs.

***Attitudes*** represent the deeper, psychological dimension of security culture. They delve into what employees genuinely believe and feel about security protocols and their role in upholding them.

“Do they perceive cybersecurity as a shared responsibility crucial for organisational survival, or view it as a bureaucratic hurdle imposed by an out-of-touch IT department?”

Attitudes shape behavioural intent and include elements such as perceived personal responsibility, trust in security leadership, belief in the effectiveness of security measures, and willingness to prioritise security over convenience. While significantly harder to quantify than raw knowledge, they can be gauged through carefully designed surveys, in-depth interviews, and focus groups that assess nuanced perceptions of importance, personal accountability, and underlying trust, or lack thereof, in the security team and leadership.

Crucially, these attitudes must be systematically compared against ***Behaviours***, which looks at the tangible, visible actions employees take in their daily work routines, regardless of what they know or claim to believe. This is where the most significant and often surprising insights are found. Behaviour measurement includes monitoring password practices, observing response to simulated phishing exercises, tracking security tool adoption rates, and reviewing incident reporting patterns.

Does an employee who attitudinally values strong security behave securely by consistently using password managers, diligently verifying request sources before transferring data, and proactively reporting suspicious phishing emails?

The disconnect between expressed attitudes and actual behaviours often reveals the most valuable insights for cultural transformation.

The final pillar, ***Enablers***, examines the organisational environment and structures that either support or hinder these secure behaviours. This includes both tangible and intangible factors: leadership actions and role modelling, the usability and integration of security tools and technology, the clarity and accessibility of policies, resource allocation for security initiatives, reward and recognition systems, and the critical presence of psychological safety.

A positive attitude and the right knowledge are rendered meaningless if cumbersome tools, conflicting priorities, insufficient resources, or a punitive culture act as powerful disablers, pushing employees toward risky workarounds that compromise security.

**The Truth Behind the Curtain: Espoused Values vs Values-in-Use**

A critical principle underpinning any effective diagnostic work is the distinction between espoused values and values-in-use, a concept foundational to understanding the true nature of organisational culture. Espoused values are the officially endorsed beliefs, rules, and principles an organisation publicly claims to hold. These are the statements found in annual reports, on company websites, and in all-staff communications, such as "We prioritise security above all else," or "We foster a blameless culture where we learn from mistakes."

Values-in-use, however, are the values actually reflected in people's behaviour, particularly when they are under pressure or faced with competing demands. An organisation may espouse a blameless culture, but if the first, instinctive response to a security incident is a managerial hunt for a culprit to sanction, the true value-in-use is blame and punishment. The diagnostic process must therefore be meticulously designed to uncover this underlying reality. We cannot simply ask, "Is your manager supportive of security initiatives?" and accept the answer at face value. We must triangulate the response by also asking behavioural questions like, "Can you describe what happened the last time someone on your team reported a security mistake?" or "What would happen if you bypassed a security control to meet an urgent deadline?" The revealing gap between what is formally said in the boardroom and what is informally done in the break room or at the desktop is where authentic cultural truth resides.

**Charting the Course: Setting Diagnostic Objectives**

Therefore, before collecting a single data point, the most important step for any leader is to set clear, strategic, and actionable objectives for the entire diagnosis. 

You must move beyond vague curiosity and ask with precision: 

*“What do I specifically need to learn, and why is this knowledge critical for our business?”*

A vague, broad goal like "to understand our security culture" will inevitably produce a vague, broad, and ultimately unactionable report that gathers dust on a shelf. Instead, diagnostic objectives should be precise, hypothesis-driven, and tightly tied to tangible business outcomes.

For example, a well-defined objective might be:

 "To determine why the adoption rate for our new multi-factor authentication solution remains stagnant below 40% despite widespread awareness and repeated communications."

This clear objective immediately dictates what to measure across the KABE framework.

It prompts an investigation into:

* **Knowledge:** Do users know how to set up and use the tool correctly?  
* **Attitudes:** Do employees believe MFA is necessary or simply an inconvenience?  
* **Behaviours:** Are users actively bypassing the control?  
* **Enablers:** Is the enrolment process burdensome, is leadership visibly using it themselves, and is adequate support available?

Another powerful objective could be: 

"To identify the root causes of chronic under-reporting of potential security incidents within our marketing and sales departments."

This focused aim would lead the diagnosis to:

* Document existing **Knowledge** about the under-reporting of security incidents.  
* Measure **Attitudes** around psychological safety and the perceived consequences of reporting.  
* Examine **Behaviours** related to past reporting habits and near-miss incidents that went unreported.  
* Evaluate **Enablers**, such as the simplicity and accessibility of the reporting tool, the clarity of the process, and most importantly, how managers have historically reacted to and treated past reports from their teams.


By rigorously defining the diagnostic scope through the comprehensive KABE model and grounding the entire process in specific, strategic objectives, the exercise transforms from a passive academic study into a powerful engine for targeted and effective intervention. It ensures you are not just listening for what you expect or hope to hear, but are systematically uncovering what you need to hear to make informed decisions. It is the disciplined process of moving from wondering why the organisational forest is withering in parts, to scientifically testing the soil, meticulously analysing the patterns of sunlight, and understanding the flow of water.

**Add Image here: Diagram showing four interlocking circles labeled Knowledge, Attitudes, Behaviours, and Enablers**

This comprehensive assessment is the essential, non-negotiable first step in cultivating a landscape where lasting, resilient security can truly take root and flourish. Just as a skilled cartographer must first understand the terrain before drawing a useful map, security leaders must understand their cultural landscape before attempting to transform it. The diagnostic scope is your compass in this endeavour, ensuring that every piece of data you collect serves a purpose and brings you closer to meaningful cultural insight.

**References**

Schein, E. H. (2010). *Organizational culture and leadership*. 4th ed. San Francisco: Jossey-Bass.

Schlienger, T. & Teufel, S. (2003). 'Analyzing information security culture: increased trust by an appropriate information security culture'. In: *Proceedings of the 14th International Workshop on Database and Expert Systems Applications*. IEEE, pp. 405-409.

Da Veiga, A. & Eloff, J. H. P. (2010). 'A framework and assessment instrument for information security culture'. *Computers & Security*, 29(2), pp. 196-207.

Thomson, K. L., van Niekerk, J. F. & von Solms, R. (2012). 'Cognitive social engineering intervention and digital security awareness training'. *Computers & Security*, 31(4), pp. 405-419.

 

 

## **3.2. The Diagnostic Toolkit: Quantitative and Qualitative Methods**

Having established what we need to measure through the KABE framework, we now turn to the crucial question of how to measure it effectively. A comprehensive understanding of security culture requires a diverse toolkit that blends quantitative methods providing statistical data with qualitative methods offering rich contextual insights. This multi-faceted approach enables triangulation of findings, building a picture that is both numerically robust and deeply human in its understanding.

**The Cultural Survey: Gauging the Broad Landscape**

The cultural survey serves as our foundational quantitative instrument, designed to capture sentiments and self-reported behaviours across large segments of the organisation. Its primary strength lies in providing measurable baseline data that can be tracked over time. However, the design of these surveys requires careful consideration, as poorly worded questions can reinforce the very fears we seek to eliminate.

The key to effective survey design lies in crafting questions that are non-punitive and psychologically safe. Since the objective is diagnosis rather than performance evaluation, we must avoid questions that might provoke defensive or dishonest responses.

For example, instead of asking "Do you follow the password policy?" which invites socially desirable answers, we might ask "How easy or difficult do you find it to create and remember passwords that meet our policy requirements?" These reframing positions the issue as a systemic challenge rather than an individual failing.

Effective surveys typically probe several critical areas using carefully constructed questions:

* For psychological safety measurement:  
  * **Question:** "If I reported a security mistake I had made, I am confident my manager would focus on learning, not blame."  
  *  **Measurement:** A five-point Likert scale from Strongly Disagree to Strongly Agree.  
* For assessing leadership commitment:  
  * **Question**: "I see senior leaders in my department consistently following our security protocols."  
  * **Measurement:** A five-point Likert scale from Strongly Disagree to Strongly Agree.  
* For understanding self-reported behaviours:  
  *  **Question:** "In the past month, how often have you reported a suspicious email?"  
  * **Measurement:** Frequency scale from Never to Always.  
* For gauging attitudes toward shared responsibility:  
  * **Question:** "I believe that cybersecurity is as much my responsibility as it is the IT departments."  
  *  **Measurement:** A five-point Likert scale from Strongly Disagree to Strongly Agree.

Including open-ended questions such as "What is the single biggest obstacle that prevents you from being more secure in your daily work?" provides invaluable qualitative context to complement the quantitative data, often revealing issues we may not have anticipated.

**Focus Groups and Interviews: Uncovering the Deeper Context**

While surveys tell us what people think, focus groups and interviews help us understand why they think it. These qualitative methods are essential for uncovering informal norms, unspoken rules, and the rich stories that define the lived experience of your organisational culture. They provide the spaces where gaps between espoused values and values-in-use become clearly visible.

The success of these conversational methods depends entirely on creating a safe space for participants. Individuals must be assured of confidentiality and must not feel they are being judged or tested. Ideally, a skilled facilitator who is not in a direct line of management over the participants should lead these sessions. The questions should be open-ended and exploratory in nature:

* "Can you tell me about a time when someone here was recognised for good security practices?"  
* "Describe what would typically happen if someone received a phishing email in your team."  
* "What messages, both formal and informal, do you receive about the importance of security compared to other priorities like speed or customer service?"


Through these dialogues, you can identify informal networks of influence, the respected colleagues whose opinions genuinely shape behaviour. You will hear the anecdotes and metaphors employees use to describe security, which serve as powerful indicators of underlying cultural assumptions. This approach moves beyond statistics to understand the human reasoning behind behaviours, potentially discovering that workarounds exist not from a lack of motivation or laziness but because of critical business processes that are incompatible with existing security controls.

**Behavioural Observation and Friction Logging: Analysing Actual Practices**

Perhaps the most revealing diagnostic method involves moving beyond what people say they do to observe what they do in practice. This approach allows us to directly witness behaviours and identify the specific friction points that drive non-compliance and workarounds.

Behavioral Observation can take both formal and informal approaches. It might involve:

* Shadowing employees from different departments to see how they integrate or bypass security controls in their actual workflows.  
* Another method involves reviewing anonymised logs from security tools to analyse patterns of use, such as how frequently password managers are utilised, how many people click on simulated phishing links, or which applications are being accessed.  
* Additionally, controlled simulations, such as a penetration testing and an incident response tabletop exercise, provide valuable behavioural data.


Complementing direct observation, is Friction Logging which represents a powerful technique that empowers employees to become active participants in the diagnostic process. By creating a simple, accessible channel, such as an anonymous form or dedicated mailbox, employees can report moments when security controls create excessive friction that forces them to choose between security and productivity. A typical log entry might state: "To share large files with our external partners, I have to put in a ticket that takes two days to be approved. Consequently, I use my personal cloud storage instead." These logs serve as a goldmine of data, pinpointing exactly where well-intentioned policies are failing in practice and driving the creation of shadow IT. They reveal critical disconnects between process design and operational reality that might otherwise remain hidden.

**Artifact Analysis: Examining Cultural Documentation**

Every organisation produces a trail of artifacts that provide tangible evidence of its culture. By systematically analysing these documents and communications, we can identify cultural clues that are often overlooked in other diagnostic methods. This approach provides a relatively objective view of the organisation's stated priorities and how it communicates about security matters.

Key artifacts worthy of analysis include several categories:

·   	**Policies and Procedures** should be examined for whether they are written in clear, accessible language or dense, technical jargon, and whether they emphasise collaboration and empowerment or are framed as lists of prohibitions and punishments. The tone of security policies often speaks volumes about the culture they intend to create.  
·   	**Internal Communications** should be reviewed for how security is presented in company-wide emails, newsletters, and intranet posts, specifically whether it is consistently framed as a threat and burden or linked to enabling business objectives and protecting colleagues. The language and imagery used in these communications reveal the narrative the organisation is building around security.  
·   	**Help-Desk Tickets** provide valuable insights through their patterns, where a high volume of tickets about a specific security tool may indicate usability or training issues, and the language users employ when asking for help reveals their attitudes and confidence levels.  
·   	Finally, **Onboarding Materials** represent a critical cultural injection point, showing whether a new hire's first introduction to security is a warm welcome from a security champion or a cold, mandatory module full of warnings.

As the Swahili proverb wisely states, "Wisdom is not like money to be tied up and hidden." True insight emerges from sharing and synthesising knowledge from every available source. By weaving together the broad trends from surveys, the deep understanding from conversations, the observable evidence of behaviours, and the silent testimony of artifacts, we can transform fragmented data points into a coherent, evidence-based narrative of your security culture. This holistic diagnostic approach ensures that subsequent improvement actions are grounded not in guesswork but in a profound, multi-dimensional understanding of the cultural landscape we aim to transform.

**References**

Edmondson, A. C. (2018). *The fearless organization: Creating psychological safety in the workplace for learning, innovation, and growth*. John Wiley & Sons.

Braun, V. & Clarke, V. (2013). *Successful qualitative research: A practical guide for beginners*. Sage.

Beyer, H. & Holtzblatt, K. (1998). *Contextual design: Defining customer-centered systems*. Morgan Kaufmann Publishers.

Spradley, J. P. (2016). *Participant observation*. Waveland Press.

 

## **3.3. Listening to the Voices: Segmenting Your Audience**

A fundamental truth in understanding organisational culture is that there is no single, monolithic experience. The security culture of an organisation is not a uniform entity but rather a complex tapestry woven from the distinct perspectives, pressures, and priorities of its various groups. To apply a one-size-fits-all diagnostic approach is to assume that a junior developer in the technology department, a sales executive on the road, a finance officer processing invoices, and the Chief Executive Officer in the boardroom all experience and influence security in the same way. This assumption is fundamentally flawed and will yield superficial, often misleading results that fail to capture the nuanced realities of how security operates across different levels and functions. A sophisticated diagnosis must therefore move beyond blanket surveys and generic questions to actively listen to the distinct voices within the organisation, segmenting the audience to understand their unique realities and contextual pressures.

**Understanding the Four Key Segments**

The failure of a uniform approach becomes starkly clear when we examine the dramatically different worlds inhabited by key organisational segments. Each group operates within distinct contextual frameworks that shape their perception of risk, security, and their role in maintaining organisational protection.

1. **The C-Suite: Strategic Altitude and Business Risk**  
   The C-Suite operates at the strategic altitude, concerned with market reputation, financial performance, regulatory compliance, and shareholder value. Their reality is framed in terms of business risk and strategic advantage, not technical vulnerabilities or specific security controls. They think in timeframes of quarters and years, not daily security alerts. Asking a CEO to rate their understanding of a specific encryption standard is not just irrelevant but demonstrates a fundamental misunderstanding of their role and concerns. Exploring their perception of cybersecurity as either a strategic enabler or a source of board-level anxiety, or their confidence in the organisation's cyber resilience as a competitive differentiator, proves far more revealing and actionable for shaping security strategy at the highest levels.

2. **Middle Management: The Critical Linchpin**  
   Middle Management represents the crucial linchpin between strategy and execution, caught between strategic directives from above and operational realities below. These team leaders, department heads, and project managers are typically measured on productivity, delivery timelines, and operational efficiency. In their reality, security can often be perceived as an obstacle to these core objectives, creating tension between compliance and performance. Diagnosing their perspective requires understanding the specific pressures they face in resource allocation, whether they feel equipped and empowered to lead their teams in security matters, and crucially, whether they inadvertently model secure behaviours or demonstrate workarounds to meet pressing deadlines. Their position as cultural amplifiers makes their buy-in critical, yet their perspective is often the most complex, balancing multiple competing priorities in their daily work.  
     
3. **IT and Security Staff: The Technical Front Line**  
   Meanwhile, IT and Security Staff inhabit the technical front lines, where their reality is defined by system configurations, threat alerts, vulnerability management, and policy enforcement. Immersed in the technical details of security controls, they often develop what might be termed a "fortress mentality," viewing the rest of the organisation not as partners but as potential threats to be controlled through technical measures. Diagnosing their culture involves understanding their levels of burnout and morale, their perception of how valued and understood their work is by the business, and whether they see their primary role as enabling safe business operations or merely policing policy violations. This group's perspective is vital for understanding the operational effectiveness of security controls and the potential for disconnection between the security function and the rest of the business.  
     
4. **Front-line Employees: The End-User Experience**  
   Finally, Front-line Employees in roles spanning from customer service and manufacturing to marketing and administration represent the ultimate end-users of security controls. Their reality is predominantly one of process completion and task achievement. For many in these roles, security is something that is "done to them"—a set of pop-ups, password prompts, and approval processes that interrupt their primary workflow rather than enabling it. For them, the most relevant questions rarely concern high-level policy but instead focus on practical enablement: does this security control help or hinder them in serving a customer, completing a manufacturing process, or achieving their core objectives? Their daily experiences provide the most honest assessment of whether security is genuinely integrated into business processes or merely superimposed upon them.

**Tailoring Diagnostic Questions for Actionable Insights**

To gather genuinely relevant and actionable data, our diagnostic questions must be meticulously tailored for each segment, speaking directly to their context and concerns.

1. **Strategic Questions for the C-Suite**  
   For the C-Suite, questions should be framed exclusively in the language of governance, business risk, and strategic advantage. Instead of technical queries like "Are you aware of our phishing training completion rates?" we ask strategic questions such as "To what extent do you see our cybersecurity resilience as influencing customer trust and competitive positioning?" or "How would you characterise the balance between security investment and business innovation in our strategic planning?" This approach elevates the conversation to their legitimate level of concern and responsibility, generating insights that can shape board-level decisions and resource allocation.

2. **Operational Questions for Middle Management**  
   For Middle Management, the diagnostic focus should centre on their dual role as cultural amplifiers and the inherent tension they navigate between security compliance and operational productivity. Effective, tailored questions include: "When your team faces conflicting pressures between a tight deadline and a security requirement, what factors influence how you navigate this tension?" or "What specific support or information from senior leadership would best enable you to champion security protocols effectively within your team without compromising performance metrics?" These questions uncover the practical challenges of translating policy into practice at the team level, revealing systemic barriers and support needs.  
     
3. **Technical and Cultural Questions for IT Staff**  
   When engaging with IT and Security Staff, we must probe beyond technical metrics to understand their connection to the broader business mission and their perception of organisational relationships. Diagnostic questions like, "To what extent do you feel the business leadership understands the operational impact of the security controls we implement?" or "What is the most common, legitimate business need that you see driving users to circumvent security policies, and how might we address this need more effectively?" can reveal critical insights into siloed mentalities, communication gaps, and opportunities for building more collaborative relationships between technical and business functions.  
     
4. **Practical Questions for Front-line Staff**  
   For Front-line Employees, diagnostics must remain firmly grounded in concrete daily experience and practical reality. Questions should be simple, direct, and focused on their workflow: "Think about the last security-related task you performed. What was your understanding of its purpose, and how did it impact your ability to complete your primary work?" or "If you could change one thing about our current security procedures to make your job easier and more secure, what would it be and why?" Their answers provide a raw, unfiltered view of where security successfully enables business activity and where it creates friction that may drive undesirable workarounds.

**Identifying Influencers and Champions**

Beyond these formal organisational segments, a critical objective of the diagnostic process involves identifying the informal influencers and potential security champions who exist within the social fabric of the organisation. These individuals are not always visible on an official organisational chart; they are the trusted colleagues others naturally turn to for advice, the early adopters of new tools and processes, the natural leaders whose opinions carry weight regardless of their formal position.

We can uncover these key figures through various methods, including social network analysis embedded in surveys by asking questions like, "Aside from the official IT helpdesk, who in the organisation do you typically ask for help or advice when you are unsure about a computer or security issue?" We can also listen for their names during interviews and focus groups, noting which individuals are repeatedly cited as helpful, knowledgeable, or influential figures when discussing technology and processes.

**Building a Nuanced Cultural Map**

Identifying and understanding these champions represents one of the most valuable outcomes of a segmented diagnostic approach. These individuals act as essential bridges between the formal security function and the broader organisational culture, serving as translators who can make security principles relatable, relevant, and actionable within their own teams and social networks. They provide organic, peer-based validation that formal communications often lack.

By understanding the unique realities of each segment and consciously engaging these informal leaders, we move from creating a simplistic, one-dimensional diagnosis to developing a rich, nuanced cultural map. This comprehensive map does not merely highlight what is broken or deficient; it reveals where the innate energy and credibility for positive change already exist within the organisation and demonstrates how to effectively channel this energy. This ensures that subsequent efforts to build a stronger, more resilient security culture are constructed on a foundation of genuine, granular understanding and are powered not just by policy, but by the authentic voices and social dynamics of the organisation itself.

**References**

Kotter, J. P. (2012). *Leading change*. Harvard Business Review Press.

Goffee, R. & Jones, G. (2018). *Why should anyone be led by you?*. Harvard Business Review Press.

Cross, R. L. & Prusak, L. (2002). 'The people who make organizations go-or stop'. *Harvard Business Review*, 80(6), pp. 105-112.

Schein, E. H. (2010). *Organizational culture and leadership*. 4th ed. San Francisco: Jossey-Bass.

## **3.4. Analysing the Data: From Raw Data to Actionable Insights**

The collection of diagnostic data such as surveys, interviews, observations, and artifacts can create a large database of voices, numbers, and stories without insights. The critical task of analysis is to transform this raw information into a coherent, evidence-based narrative that reveals the true state of your security culture. This process is less about crunching numbers and more about pattern recognition, synthesis, and insight generation. It requires moving between the bird's-eye view of statistical trends and the ground-level reality of human experience, weaving together disparate threads of evidence to create a tapestry of understanding. The goal is not merely to describe what is, but to illuminate why it is, and to point clearly toward what could be.

**Triangulation: The Foundation of Reliable Insight**

The cornerstone of robust cultural analysis is **t**riangulation and the practice of using multiple, independent sources of data to verify and enrich your findings. No single data source provides a complete or perfectly reliable picture. Survey statistics might tell you *what* is happening, but interview quotes reveal *why* it's happening, and behavioural observations confirm *if* it's *really* happening. When these different lines of inquiry converge on the same conclusion, you can have high confidence in your diagnosis.

Consider a scenario where a survey indicates that 80% of employees in the Finance department agree with the statement, "I feel comfortable reporting a security mistake." This is a promising quantitative data point. However, during focus groups with the same department, you repeatedly hear comments like, "Well, you can report it, but you'll never hear the end of it from the Vice President of the Department," or "I reported a misdirected email once, and my manager made me feel like I had jeopardised the entire company." These qualitative quotes directly contradict the survey's positive sentiment, revealing a culture where psychological safety is espoused but not enacted.

Further behavioural evidence might solidify this finding. An analysis of help-desk tickets could show that the Finance department has the lowest rate of self-reported incidents in the company, despite handling some of the most sensitive data. This behavioural data point, what people *actually do,* triangulates with the interview quotes to tell a more truthful story than the survey data alone: a culture of silent fear, not open reporting. The combined story is one of perceived risks in reporting, which the survey alone would have completely missed.

The analytical process, therefore, involves constantly cross-referencing:

* **Quantitative with Qualitative:** Do the survey scores align with the stories people tell? If not, why might there be a disconnect?  
* **Espoused with Observed:** Do the values stated in policies and leadership communications match the behaviours witnessed in shadowing exercises and friction logs?  
* **Formal with Informal:** Do the official processes documented in artifacts align with the informal workarounds and norms described in interviews?

It is in the tensions and contradictions between these different data sources that some of the most profound cultural insights are often found.

**Identifying Cultural Archetypes: A Diagnostic Compass**

To make sense of the patterns emerging from the data, it is invaluable to use a framework of cultural archetypes. These archetypes, powerfully adapted from Ron Westrum's seminal work on safety cultures, provide a diagnostic compass that helps categorise and understand the fundamental character of an organisation's security culture. While cultures are rarely pure types, they tend to gravitate toward one of three dominant patterns: Pathological, Bureaucratic, or Generative.

**1\. The Pathological Culture (Blame-Oriented)**  
In a pathological security culture, the primary motivations are fear and power. Information is hoarded as a source of individual power, and failure is hidden and punished. Messengers of bad news—such as an employee who reports a phishing click or a configuration error—are "shot." The organisational response to an incident is not "What can we learn?" but "Who can we blame?" Leadership in this culture is often authoritarian and secretive. Innovation in security is stifled because experimentation carries the high risk of career-limiting failure. You will identify this archetype in your data through interview quotes filled with fear ("I'd never admit that to my manager"), observations of widespread shadow IT used to avoid scrutiny, and survey results showing extremely low scores for psychological safety and trust in leadership.

**2\. The Bureaucratic Culture (Rule-Oriented)**  
A bureaucratic security culture is characterised by rules, processes, and compartments. It is not overtly malicious like the pathological culture, but it is inflexible and slow. The security function operates in silos, and cooperation across departments is hindered by procedural walls and turf protection. Failure in this culture leads to a procedural response: more rules, more checklists, and more mandatory training. The motto is "We followed the process," even if the process failed. Leadership is often detached, managing by policy rather than engagement. Innovation is slow and must navigate a labyrinth of compliance hurdles. Evidence of a bureaucratic culture appears in data showing high policy awareness but low understanding of the underlying risk principles, friction logs filled with complaints about slow approval processes, and interview comments like, "That's not my department's problem," or "I just do what the policy says."

**3\. The Generative Culture (Responsibility-Oriented)**  
In a generative security culture, the overarching goal is mission performance, and security is seen as an enabler of that mission. Information is actively shared to improve collective performance. Failure leads to a reflective response: a deep, blameless root-cause analysis focused on fixing systemic issues, not punishing individuals. Leadership is visible, engaged, and models secure behaviours. There is a high degree of cooperation across departmental boundaries, and people are rewarded for speaking up about concerns. Innovation is encouraged and carefully managed. Signs of a generative culture in your data include high levels of psychological safety in surveys, a high volume of reported near-misses and suspicious emails (indicating trust in the reporting system), interview quotes that emphasise shared responsibility ("We're all in this together"), and observations of cross-functional teams collaboratively solving security challenges.

The following table provides a clear comparison of these archetypes across key cultural dimensions, serving as a reference during your analysis.

**Table: Cultural Archetype Comparison**

| Dimension | Pathological (Blame-Oriented) | Bureaucratic (Rule-Oriented) | Generative (Responsibility-Oriented) |
| :---- | :---- | :---- | :---- |
| **Response to Failure** | Find and punish the culprit. Hide failures. | Write a new rule or procedure. Focus on process compliance. | Conduct blameless root-cause analysis. Learn and improve the system. |
| **Information Flow** | Hoarded for power. Messengers are "shot." | Restricted by silos and formal channels. | Actively and freely shared. Messengers are trained and rewarded. |
| **Leadership Style** | Authoritarian, secretive, focused on individual reputation. | Detached, managerial, focused on policy and precedent. | Engaged, visible, curious, models desired behaviours. |
| **Cooperation** | Cross-functional cooperation is low and discouraged. | Cooperation is limited by formal rules and turf protection. | High, cross-functional collaboration is expected and rewarded. |
| **Innovation & Risk** | Highly risky for individuals, therefore stifled. | Slow, burdened by bureaucracy and compliance. | Encouraged and managed as a necessary part of improvement. |
| **Primary Goal** | Protect individual power and position. | Protect the department and follow the rules. | Achieve the mission safely and effectively. |

 

**Mapping Cultural Strengths, Weaknesses, and Latent Opportunities**

With the archetypes as a guide and triangulated data in hand, the final stage of analysis is to create a practical map of the cultural landscape. This map should not be a simple binary of "good" and "bad" but a nuanced portrait that identifies three key elements: strengths to leverage, weaknesses to address, and latent opportunities to cultivate.

**1\. Mapping Strengths: The Foundations to Build Upon**  
Cultural strengths are the positive, established patterns that already work in your favour. They are the assets you can leverage to drive further improvement. A strength might be:

* A specific department (e.g., Engineering) that already exhibits highly generative traits, serving as a potential model for the rest of the organisation.  
* A strong, positive attitude toward security among front-line employees, indicating a readiness to engage if enabled properly.  
* A leadership team that is genuinely curious and willing to learn, as evidenced by their interview responses and willingness to participate in the diagnosis.  
* A highly effective and trusted Security Champion in a key business unit, identified through social network analysis.

The analysis must pinpoint *where* these strengths reside and *why* they are effective, so they can be replicated and scaled.

**2\. Mapping Weaknesses: The Vulnerabilities to Address**  
Weaknesses are the cultural patterns that actively undermine security. They are the systemic root causes of risky behaviour and compliance failures. A weakness could be:

* A pathological culture in the sales team, driven by a high-pressure VP, leading to rampant use of unapproved cloud tools.  
* A bureaucratic logjam in the IT service desk, creating so much friction that employees are forced to find dangerous workarounds.  
* A critical gap in knowledge among a newly acquired subsidiary, revealed by survey scores and confirmed in interviews.  
* A profound lack of psychological safety in the operations centre, leading to the under-reporting of incidents.

The analysis must connect these weaknesses to observable business risks and prioritise them based on their impact and the organisation's capacity to change them.

**3\. Mapping Latent Opportunities: The Seeds of Transformation**  
Perhaps the most sophisticated output of analysis is the identification of latent opportunities. These are not current strengths, but rather untapped potentials or emerging positive trends that could be nurtured into significant cultural assets. An opportunity might be:

* **Latent Champions:** Individuals who are not yet formal champions but are identified as influential and positively inclined toward security in the social network analysis. These are people who could be recruited and empowered.  
* **Frustration with the Status Quo:** Widespread frustration with cumbersome bureaucratic processes, as seen in friction logs, can be a powerful latent energy for change. This frustration can be channelled into co-designing better, more user-friendly security controls.  
* **A "Bright Spot":** A small team that has developed an innovative, secure workaround to a common problem. This local solution could be studied, refined, and turned into a new organisational standard.  
* **A Readiness for Clarification:** Interview data that shows confusion about "why" certain policies exist, indicating an opportunity for a communication campaign that connects security controls to business outcomes, which could dramatically increase buy-in.

By mapping these strengths, weaknesses, and opportunities, the analysis provides a clear and actionable strategic roadmap. It moves the conversation from "We have a people problem" to "We have a systemic issue in the sales department that is eroding our security posture, but we have a potential model for success in our engineering department and a pool of latent champions we can activate." This is the ultimate value of transforming raw information into actionable insight: it replaces vague anxiety with targeted intention and provides the evidentiary foundation for building a security culture that is not just compliant, but resilient, adaptive, and generative.

**References**

Westrum, R. (2004). 'A typology of organisational cultures'. *Quality and Safety in Health Care*, 13(Suppl II), pp. ii22-ii27.

Braun, V. & Clarke, V. (2013). *Successful qualitative research: A practical guide for beginners*. Sage.

Edmondson, A. C. (2018). *The fearless organization: Creating psychological safety in the workplace for learning, innovation, and growth*. John Wiley & Sons.

Patton, M. Q. (2015). *Qualitative research & evaluation methods*. 4th ed. Sage Publications.

 

## **3.5. The Cultural Baseline Report: Telling the Story of Your Findings**

The culmination of the diagnostic phase is not merely a dataset; it is a story. The Cultural Baseline Report is the vessel for this story, a strategic document that translates complex, multi-faceted data into a compelling narrative for leadership and stakeholders. Its purpose is not to archive findings but to catalyse action. A well-crafted report does more than present facts; it builds a shared understanding, creates a sense of urgency and possibility, and charts a clear course forward (Kotter, 2012). It moves the conversation from "What did we find?" to "This is what it means, and this is what we must do." Crafting such a report requires a deliberate shift from the mindset of a data analyst to that of a strategic storyteller, one who understands that to change culture, one must first capture the hearts and minds of those who shape it.

**Synthesising Insights into a Compelling Narrative**

The most common failure of diagnostic reports is the "data dump"—a dispassionate list of charts, tables, and disjointed observations that overwhelms the reader and obscures meaning. The alternative is a narrative structure that guides the audience through a logical and persuasive journey. This narrative should be built around a central thesis, a single, powerful statement that encapsulates the core finding. For example: "Our diagnostic reveals an organisation with strong technical controls but a cultural undercurrent of fear that drives risky workarounds and silences our most valuable early-warning system: our people."

This central thesis is then supported by a clear narrative arc:

1. **The Setting: Where We Are Today.** Begin by grounding the report in the current reality. Briefly describe the diagnostic process and the scope of work, building credibility. Then, paint a concise but vivid picture of the overall cultural landscape, using the archetype framework (Pathological, Bureaucratic, Generative) as an anchor (Westrum, 2004). Is the culture primarily one of blame, bureaucracy, or shared responsibility? This sets the stage for the detailed findings to come.  
2. **The Journey: The Evidence and Its Meaning.** This is the core of the report, where you present your triangulated findings. Crucially, do not organise this by methodology (e.g., "Survey Results," followed by "Interview Themes"). Instead, organise it by the key cultural pillars or the strategic objectives you set out to investigate (Patton, 2015).  
   * For example, a section titled "Leadership and Psychological Safety" would weave together: survey data on trust in management; poignant quotes from interviews describing reactions to past mistakes; and behavioural evidence from friction logs showing where a lack of safety drives shadow IT.  
   * Another section, "The Gap Between Knowing and Doing," could juxtapose high knowledge-test scores with observations of widespread policy non-compliance, using interview quotes to explain the "why"—the friction, the competing priorities, the perceived lack of relevance.

This integrated approach tells a cohesive story for each theme, demonstrating how different types of evidence converge to reveal a deeper truth.

3. **The Destination: A Path Forward.** The narrative must culminate in a clear and actionable conclusion. This is not the place for new data, but for synthesis and interpretation. Revisit the central thesis in light of the evidence presented and pivot towards the future. This section introduces the map of **cultural strengths, weaknesses, and latent opportunities**, framing them as the key inputs for the subsequent strategy and planning phase.

**Visualising Data Effectively: Creating Emotional and Intellectual Impact**

A powerful narrative is greatly amplified by thoughtful visualisation. The goal of visualisation is not to decorate the report but to make complex data instantly understandable and memorable (Few, 2012). Different types of data call for different visual strategies:

* **Charts for Trends and Comparisons:** Use simple, clean bar charts or radar charts to compare survey scores across different departments or against industry benchmarks. A line graph showing the correlation between psychological safety scores and incident reporting rates can tell a powerful story at a glance. Avoid cluttered pie charts or over-complicated visuals that require lengthy explanation.  
* **Heat Maps for Cultural Topography:** A heat map is an exceptionally effective tool for visualising the cultural landscape across the organisation. Imagine a grid where rows represent different departments (for example: Finance, Engineering, Sales or HR) and columns represent key cultural dimensions (for example: Psychological Safety, Leadership Commitment or Secure Behaviours). I would recommend that you colour-code each cell, from red (this would mean weak or pathological) to amber (this would mean neutral or bureaucratic) to green (this would mean strong or generative). This provides an immediate, intuitive overview of where cultural strengths are concentrated and where the most significant vulnerabilities lie. This visual quickly answers the stakeholder's question: "Where should we focus?"  
* **Quotes and Anecdotes for Human Voice:** Quantitative data appeals to the logical mind, but qualitative quotes appeal to the heart. Strategically placed, verbatim quotes from interviews and focus groups are not mere illustrations; they are evidence (Braun & Clarke, 2013). A single quote like, "I'd rather risk a breach than face my manager's anger over a mistake," has more emotional impact than a dozen graphs on fear of reporting. These voices make the data human, tangible, and unforgettable. Consider using a "quote cloud" or sidebars to highlight these powerful testimonials.  
* **The "Espoused vs. In-Use" Contrast:** A simple but powerful two-column table can vividly illustrate the gap between official values and actual behaviours. On one side, list quotes from policy documents or leadership speeches (Espoused Values). On the other, list corresponding quotes from interviews or observations (Values-in-Use). The dissonance is starkly clear and builds a compelling case for change.

**Framing Findings as Opportunities for Growth**

The tone of the report is perhaps the single most important factor in determining whether it leads to action or gathers dust on a shelf. A report that frames findings as a list of failures and deficiencies will trigger defensiveness, disengagement, and a search for scapegoats. The objective is psychological safety at the organisational level; the report itself must model this principle (Edmondson, 2018).

The reframing is simple but profound: every "weakness" is an "opportunity for growth." This is not mere semantics; it is a fundamental shift in perspective that unlocks energy and collaboration.

* Instead of: "The Sales department has a pathological culture of blame."  
* Frame it as: "We have a significant opportunity to build psychological safety within the Sales department. By empowering sales leaders with new skills and aligning incentives, we can unlock their potential to become powerful advocates for security, turning a current vulnerability into a future strength."  
* Instead of: "Employees do not understand the security policies."  
* Frame it as: "We have an opportunity to make our security guidance more accessible and relevant. By translating policies into practical, role-based guidance, we can close the knowing-doing gap and empower every employee to make secure choices effortlessly."

This opportunity-centric framing does the following:

1. **Reduces Defensiveness:** It signals that the diagnosis is about improving systems and processes, not judging people or departments. It invites leadership to solve a problem together, rather than defend against an accusation.  
2. **Creates Agency and Hope:** A list of failures is disempowering. A list of opportunities is energising. It answers the "So what?" with "Here is what we can achieve," fostering a sense of agency and positive momentum.  
3. **Focuses on the Future:** It naturally leads into the next phase of the journey. The report concludes not with a dead end of problems, but with a starting line for a strategic initiative focused on realising these latent opportunities.

The Cultural Baseline Report is the critical bridge between diagnosis and transformation. It is a strategic tool that, when crafted with narrative power, visual clarity, and a constructive tone, does more than communicate findings—it builds the coalition and creates the will necessary to embark on the challenging yet rewarding work of building a generative, resilient, and ultimately human-centric security culture. It is the story that marks the end of the beginning, setting the stage for the deliberate and collective work of cultivation that lies ahead.

**References**

Braun, V. & Clarke, V. (2013). *Successful qualitative research: A practical guide for beginners*. Sage.

Edmondson, A. C. (2018). *The fearless organization: Creating psychological safety in the workplace for learning, innovation, and growth*. John Wiley & Sons.

Few, S. (2012). *Show me the numbers: Designing tables and graphs to enlighten*. Analytics Press.

Kotter, J. P. (2012). *Leading change*. Harvard Business Review Press.

Patton, M. Q. (2015). *Qualitative research & evaluation methods*. 4th ed. Sage Publications.

Westrum, R. (2004). 'A typology of organisational cultures'. *Quality and Safety in Health Care*, 13(Suppl II), pp. ii22-ii27.

## **3.6. From Diagnosis to Prescription** 

The diagnostic journey we have undertaken is akin to a physician conducting a thorough examination before reaching for a prescription pad. We have moved from vague suspicions about our security culture to a precise, evidence based understanding of its very fabric. This phase has equipped us with more than just data. It has provided a clear eyed diagnosis of the cultural forces that either fortify or undermine our organisational resilience. The key takeaway is unequivocal. We cannot fix what we do not understand, and now, we understand.

This process has revealed that a robust security culture is a multidimensional construct, best understood through the KABE model. This framework examines the dynamic interplay of Knowledge, Attitudes, Behaviours, and Enablers. We have learned to listen to the distinct voices within our organisation, segmenting our audience to appreciate the different realities of various groups from the C suite to front line employees. Through careful triangulation of surveys, interviews, observations, and artifacts, we have moved beyond assumptions to uncover the ground truth. We can now identify whether our culture tends towards the pathological blame oriented model, the bureaucratic rule oriented approach, or the generative responsibility oriented ideal. Most importantly, we have synthesised these insights into a Cultural Baseline Report that tells a compelling story not of failure, but of latent potential. This report maps clear strengths to leverage, weaknesses to address, and opportunities to cultivate.

However, this diagnosis is not an end in itself. It represents the essential foundation upon which all subsequent efforts must be built. To stop at diagnosis would be like a farmer meticulously testing the soil only to never plant a seed. There is an Akan proverb that offers wisdom for this moment. It says, "By the time the fool has learned the rules, the game has ended." Our diagnosis ensures we understand the rules of our cultural landscape now, so we do not arrive too late to effect meaningful change. The real work of cultivation begins now. The insights generated in this chapter are not meant to be archived. They are designed to be activated, providing the critical inputs for the targeted change strategy that will form the heart of the next section of our journey.

The detailed cultural map we have created will directly feed into the behavioural design and change management strategies to come. Our understanding of specific knowledge gaps will inform the creation of just in time, role based training that replaces generic awareness campaigns. The attitudes and perceptions we uncovered, especially around psychological safety and leadership commitment, will shape the narrative and messaging of our change initiative. This ensures our communications resonate rather than repel. The observed behaviours and documented friction points provide a direct blueprint for our enablement strategy, showing us precisely which tools to simplify, which processes to streamline, and where to invest in technology that makes the secure path the easy path.

The identified cultural archetypes will guide our overall approach. For a pathological culture, our primary focus will be on building trust and psychological safety. For a bureaucratic environment, we will work on breaking down silos and empowering local decision making. The latent opportunities and potential champions we discovered will become the vanguard of our change effort. These early adopters can model new behaviours and influence their peers. As the Swahili saying wisely observes, "A single stick may smoke, but it will not burn alone." Our champions are these initial sticks that will create the fire of collective change. However, they need the right conditions to flourish. They require the breath of leadership support and the kindling of enabling systems to ignite a lasting transformation.

In the forthcoming chapters, we will transition from diagnosis to prescription. We will explore how to use the principles of behavioural science, including nudge theory, habit design, and social influence, to deliberately design an environment that promotes secure behaviours effortlessly. We will delve into change management frameworks that guide us in mobilising our organisation, building a coalition, and sustaining momentum. The diagnosis has given us our precise coordinates. The subsequent chapters will provide the vehicle, the fuel, and the roadmap to move deliberately from our current reality to our desired future. We are building toward a future where security is not an imposed set of rules, but a deeply ingrained, shared value that enables the entire organisation to thrive securely in a complex digital landscape. The examination is complete. The treatment plan now begins.

**References**

Edmondson, A. C. (2018). *The fearless organization: Creating psychological safety in the workplace for learning, innovation, and growth*. John Wiley & Sons.

Kotter, J. P. (2012). *Leading change*. Harvard Business Review Press.

Thaler, R. H. & Sunstein, C. R. (2008). *Nudge: Improving decisions about health, wealth, and happiness*. Yale University Press.
